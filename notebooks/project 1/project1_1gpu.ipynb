{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw4F7Z0_vK7S",
        "outputId": "193cca7a-f36b-451b-f2f1-f699622883ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "SEED = 1234\n",
        "ROOT = \".\"\n",
        "MODEL_NAME = \"VGG16\"\n",
        "SENARIO = \"1GPU\"\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\"\"\"# 2. Initialize the DDP Environment\"\"\"\n",
        "\n",
        "def setup(rank, world_size):\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'  # Change this to the master node's IP address if using multiple machines\n",
        "    os.environ['MASTER_PORT'] = '12345'  # Pick a free port on the master node\n",
        "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
        "\n",
        "def cleanup():\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "\"\"\"# 3. Define a Model.\"\"\"\n",
        "\n",
        "\n",
        "# define the CNN architecture\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def create_model():\n",
        "\n",
        "    for param in vgg16.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    n_inputs = vgg16.classifier[6].in_features\n",
        "    last_layer = nn.Linear(n_inputs, 10)\n",
        "    vgg16.classifier[6] = last_layer\n",
        "    print(f'The model has {count_parameters(vgg16):,} trainable parameters')\n",
        "    model = vgg16\n",
        "    return model\n",
        "\n",
        "\"\"\"# 4. Create a Dummy Dataset\"\"\"\n",
        "\n",
        "def create_dataloader(rank, world_size, batch_size=BATCH_SIZE, root = ROOT, max_length = 256):\n",
        "    data_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.ToTensor()])\n",
        "    ## load the data with\n",
        "    outdir = f\"{root}/data\"\n",
        "    if rank == 0 and not os.path.exists(outdir):\n",
        "        train_data = datasets.CIFAR10(outdir, train=True,\n",
        "                                      download=True, transform=data_transform)\n",
        "        test_data = datasets.CIFAR10(outdir, train=False,\n",
        "                                    download=True, transform=data_transform)\n",
        "\n",
        "    dist.barrier()  # Ensure all processes wait for the dataset to be downloaded\n",
        "\n",
        "    train_data = datasets.CIFAR10(outdir, train=True,\n",
        "                                      download=True, transform=data_transform)\n",
        "    test_data = datasets.CIFAR10(outdir, train=False,\n",
        "                                    download=True, transform=data_transform)\n",
        "    ## create the validation split\n",
        "    VALID_RATIO = 0.9\n",
        "\n",
        "    n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "    n_valid_examples = len(train_data) - n_train_examples\n",
        "    train_data, valid_data = data.random_split(train_data,\n",
        "                                           [n_train_examples, n_valid_examples])\n",
        "\n",
        "    if rank == 0:\n",
        "        print(f'Number of training examples: {len(train_data)}')\n",
        "        print(f'Number of validation examples: {len(valid_data)}')\n",
        "        print(f'Number of testing examples: {len(test_data)}')\n",
        "\n",
        "\n",
        "    ## Creating Data Loaders\n",
        "\n",
        "    train_sampler = DistributedSampler(train_data, num_replicas=world_size, rank=rank, shuffle=True)\n",
        "    val_sampler = DistributedSampler(valid_data, num_replicas=world_size, rank=rank)\n",
        "\n",
        "    train_dataloader = data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, pin_memory=True) #use num_workers > 0 for better performance\n",
        "    val_dataloader = data.DataLoader(valid_data, batch_size=batch_size, sampler=val_sampler, pin_memory=True) #use num_workers > 0 for better performance\n",
        "    test_dataloader = data.DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True) #no sampling for test dataset\n",
        "    return train_dataloader, val_dataloader, test_dataloader\n",
        "\n",
        "\"\"\"# 5. Implement the Training Loop\n",
        "\n",
        "## a. Help function\n",
        "\"\"\"\n",
        "\n",
        "RESULTS_FILE = f\"{ROOT}/{MODEL_NAME}_{EPOCHS}epochs_{SENARIO}.json\"\n",
        "\n",
        "def log_results(scenario, results):\n",
        "    \"\"\"\n",
        "    Save results to a JSON file for comparison across scenarios.\n",
        "    \"\"\"\n",
        "    if os.path.exists(RESULTS_FILE):\n",
        "        with open(RESULTS_FILE, 'r') as f:\n",
        "            all_results = json.load(f)\n",
        "    else:\n",
        "        all_results = {}\n",
        "\n",
        "    all_results[scenario] = results\n",
        "\n",
        "    with open(RESULTS_FILE, 'w') as f:\n",
        "        json.dump(all_results, f, indent=4)\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim=True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\"\"\"## b. train function\"\"\"\n",
        "def train(model, iterator, optimizer, criterion, rank):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    i=0\n",
        "    for (x, y) in tqdm(iterator, desc=f\"Training on the rank {rank}...\", leave=False):\n",
        "\n",
        "        x = x.to(rank)\n",
        "        y = y.to(rank)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x)\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        if i % 50 == 0 and rank == 0 :\n",
        "            print(f\"- On Training: {i} was passed over  {len(iterator)}\")\n",
        "        i+=1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "\"\"\"## c. Validation function\"\"\"\n",
        "def evaluate(model, iterator, criterion, rank, mode = \"Evaluating\"):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    i=0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in tqdm(iterator, desc=f\"{mode} on the rank {rank} ...\", leave=False):\n",
        "\n",
        "            x = x.to(rank)\n",
        "            y = y.to(rank)\n",
        "\n",
        "            y_pred = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "            if i % 50 == 0 and rank == 0:\n",
        "                print(f\"- On {mode}: {i} was passed over  {len(iterator)}\")\n",
        "            i+=1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "\"\"\"## d. Main loop\"\"\"\n",
        "\n",
        "outdir = f'{ROOT}/model/'\n",
        "if not os.path.exists(outdir):\n",
        "    os.makedirs(outdir)\n",
        "\n",
        "def main_train(rank, world_size, root = outdir, num_epochs = EPOCHS, model_name = MODEL_NAME):\n",
        "    ## a. Set up the distributed process groups\n",
        "    setup(rank, world_size)\n",
        "    print(f\"Process {rank} initialized.\")\n",
        "\n",
        "    # setup mp_model and devices for this process\n",
        "\n",
        "\n",
        "    ## b. Create Model, DataLoader\n",
        "    train_dataloader, val_dataloader, test_dataloader = create_dataloader(rank, world_size)\n",
        "    model = create_model().to(rank)\n",
        "\n",
        "    ## c. Wrap the model with DistributedDataParallel\n",
        "    ddp_model = DDP(model, device_ids=[rank])\n",
        "\n",
        "    ## d. Loss and Optimizer\n",
        "    #LR = 5e-4\n",
        "    criterion = nn.CrossEntropyLoss().to(rank) # Move loss to GPU\n",
        "    optimizer = optim.Adam(ddp_model.parameters(), lr=0.01)\n",
        "\n",
        "    ## e. Training Loop\n",
        "    best_valid_loss = float('inf')\n",
        "    training_times = []\n",
        "    train_losses = []\n",
        "    train_accurcy = []\n",
        "    validation_times = []\n",
        "    validation_losses = []\n",
        "    validation_accurcy = []\n",
        "\n",
        "    epoch_times = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_epoch_time = time.monotonic()\n",
        "        start_time = time.monotonic()\n",
        "\n",
        "        train_loss, train_acc = train(ddp_model, train_dataloader, optimizer, criterion, rank)\n",
        "        train_time = time.monotonic() - start_time\n",
        "        training_times.append(train_time)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accurcy.append(train_acc)\n",
        "\n",
        "        start_time = time.monotonic()\n",
        "        valid_loss, valid_acc = evaluate(ddp_model, val_dataloader, criterion, rank)\n",
        "        val_time = time.monotonic() - start_time\n",
        "        validation_times.append(val_time)\n",
        "        validation_losses.append(valid_loss)\n",
        "        validation_accurcy.append(valid_acc)\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(ddp_model.state_dict(), f'{root}mlp-model.pt')\n",
        "\n",
        "        end_time = time.monotonic()\n",
        "        e_time = end_time - start_epoch_time\n",
        "        epoch_times.append(e_time)\n",
        "        epoch_mins, epoch_secs = epoch_time(start_epoch_time, end_time)\n",
        "\n",
        "        print(f'--------------|     On process {rank}      |----------------')\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    ## f. test after train\n",
        "    ddp_model.load_state_dict(torch.load(f'{root}mlp-model.pt'))\n",
        "    start_time = time.monotonic()\n",
        "    test_loss, test_acc = evaluate(ddp_model, test_dataloader, criterion, rank, mode = \"Testing\")\n",
        "    test_time = time.monotonic() - start_time\n",
        "    print(f'Test results on process {rank}: Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "\n",
        "    # Log results\n",
        "    results = {\n",
        "        \"world_size\": world_size,\n",
        "        \"rank\": rank,\n",
        "        \"training_times\": training_times,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"train_accurcy\": train_accurcy,\n",
        "        \"validation_times\": validation_times,\n",
        "        \"validation_losses\": validation_losses,\n",
        "        \"validation_accurcy\": validation_accurcy,\n",
        "        \"test_time\": test_time,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"epoch_times\": epoch_times\n",
        "     }\n",
        "\n",
        "    scenario = f\"model_{model_name}_epochs_{num_epochs}_{world_size}_GPUs_rank_{rank}\"\n",
        "    log_results(scenario, results)\n",
        "    dist.barrier()\n",
        "\n",
        "    cleanup()\n",
        "    print(f'Process {rank} finished training.')\n",
        "\n",
        "\"\"\"# 6. Main Execution\"\"\"\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    def main():\n",
        "        world_size = torch.cuda.device_count()\n",
        "        print(f'Total number of devices detected: {world_size}')\n",
        "\n",
        "        if world_size >= 1:\n",
        "            #start the training process on all available GPUs\n",
        "\n",
        "            if world_size > 1:\n",
        "                #start the training process on all available GPUs\n",
        "\n",
        "                mp.spawn(\n",
        "                    main_train,\n",
        "                    args=(world_size,),\n",
        "                    nprocs=world_size,\n",
        "                    join=True\n",
        "                )\n",
        "            else:\n",
        "                #run training on single GPU\n",
        "                main_train(rank=0, world_size=1)\n",
        "\n",
        "        else:\n",
        "            print('no GPUs found. Please make sure you have configured CUDA correctly')\n",
        "\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjcdf4BsvWU6",
        "outputId": "55f628a2-b04a-40a4-fe3f-937aaee3b327"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Total number of devices detected: 1\n",
            "Process 0 initialized.\n",
            "[rank0]:[W110 10:31:29.975779797 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 45000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 10000\n",
            "The model has 119,586,826 trainable parameters\n",
            "Training on the rank 0...:   0% 0/704 [00:00<?, ?it/s]- On Training: 0 was passed over  704\n",
            "Training on the rank 0...:   7% 50/704 [00:23<04:47,  2.28it/s]- On Training: 50 was passed over  704\n",
            "Training on the rank 0...:  14% 100/704 [00:45<04:27,  2.26it/s]- On Training: 100 was passed over  704\n",
            "Training on the rank 0...:  21% 150/704 [01:07<04:14,  2.18it/s]- On Training: 150 was passed over  704\n",
            "Training on the rank 0...:  28% 200/704 [01:29<03:38,  2.31it/s]- On Training: 200 was passed over  704\n",
            "Training on the rank 0...:  36% 250/704 [01:51<03:17,  2.30it/s]- On Training: 250 was passed over  704\n",
            "Training on the rank 0...:  43% 300/704 [02:15<02:56,  2.29it/s]- On Training: 300 was passed over  704\n",
            "Training on the rank 0...:  50% 350/704 [02:37<02:34,  2.30it/s]- On Training: 350 was passed over  704\n",
            "Training on the rank 0...:  57% 400/704 [02:59<02:17,  2.21it/s]- On Training: 400 was passed over  704\n",
            "Training on the rank 0...:  64% 450/704 [03:21<01:53,  2.24it/s]- On Training: 450 was passed over  704\n",
            "Training on the rank 0...:  71% 500/704 [03:44<01:29,  2.29it/s]- On Training: 500 was passed over  704\n",
            "Training on the rank 0...:  78% 550/704 [04:06<01:10,  2.20it/s]- On Training: 550 was passed over  704\n",
            "Training on the rank 0...:  85% 600/704 [04:29<00:45,  2.27it/s]- On Training: 600 was passed over  704\n",
            "Training on the rank 0...:  92% 650/704 [04:51<00:24,  2.22it/s]- On Training: 650 was passed over  704\n",
            "Training on the rank 0...:  99% 700/704 [05:13<00:01,  2.18it/s]- On Training: 700 was passed over  704\n",
            "Evaluating on the rank 0 ...:   0% 0/79 [00:00<?, ?it/s]- On Evaluating: 0 was passed over  79\n",
            "Evaluating on the rank 0 ...:  63% 50/79 [00:19<00:11,  2.56it/s]- On Evaluating: 50 was passed over  79\n",
            "--------------|     On process 0      |----------------\n",
            "Epoch: 01 | Epoch Time: 5m 52s\n",
            "\tTrain Loss: 4.042 | Train Acc: 11.85%\n",
            "\t Val. Loss: 2.218 |  Val. Acc: 14.85%\n",
            "Training on the rank 0...:   0% 0/704 [00:00<?, ?it/s]- On Training: 0 was passed over  704\n",
            "Training on the rank 0...:   7% 50/704 [00:22<05:00,  2.18it/s]- On Training: 50 was passed over  704\n",
            "Training on the rank 0...:  14% 100/704 [00:44<04:28,  2.25it/s]- On Training: 100 was passed over  704\n",
            "Training on the rank 0...:  21% 150/704 [01:06<03:59,  2.31it/s]- On Training: 150 was passed over  704\n",
            "Training on the rank 0...:  28% 200/704 [01:28<03:40,  2.28it/s]- On Training: 200 was passed over  704\n",
            "Training on the rank 0...:  36% 250/704 [01:51<03:28,  2.17it/s]- On Training: 250 was passed over  704\n",
            "Training on the rank 0...:  43% 300/704 [02:13<03:11,  2.11it/s]- On Training: 300 was passed over  704\n",
            "Training on the rank 0...:  50% 350/704 [02:35<02:39,  2.23it/s]- On Training: 350 was passed over  704\n",
            "Training on the rank 0...:  57% 400/704 [02:58<02:12,  2.29it/s]- On Training: 400 was passed over  704\n",
            "Training on the rank 0...:  64% 450/704 [03:20<01:52,  2.26it/s]- On Training: 450 was passed over  704\n",
            "Training on the rank 0...:  71% 500/704 [03:43<01:35,  2.14it/s]- On Training: 500 was passed over  704\n",
            "Training on the rank 0...:  78% 550/704 [04:05<01:09,  2.21it/s]- On Training: 550 was passed over  704\n",
            "Training on the rank 0...:  85% 600/704 [04:27<00:45,  2.29it/s]- On Training: 600 was passed over  704\n",
            "Training on the rank 0...:  92% 650/704 [04:50<00:23,  2.30it/s]- On Training: 650 was passed over  704\n",
            "Training on the rank 0...:  99% 700/704 [05:12<00:01,  2.27it/s]- On Training: 700 was passed over  704\n",
            "Evaluating on the rank 0 ...:   0% 0/79 [00:00<?, ?it/s]- On Evaluating: 0 was passed over  79\n",
            "Evaluating on the rank 0 ...:  63% 50/79 [00:19<00:12,  2.35it/s]- On Evaluating: 50 was passed over  79\n",
            "--------------|     On process 0      |----------------\n",
            "Epoch: 02 | Epoch Time: 5m 57s\n",
            "\tTrain Loss: 2.290 | Train Acc: 13.15%\n",
            "\t Val. Loss: 2.135 |  Val. Acc: 16.59%\n",
            "Training on the rank 0...:   0% 0/704 [00:00<?, ?it/s]- On Training: 0 was passed over  704\n",
            "Training on the rank 0...:   7% 50/704 [00:22<04:48,  2.27it/s]- On Training: 50 was passed over  704\n",
            "Training on the rank 0...:  14% 100/704 [00:44<04:24,  2.28it/s]- On Training: 100 was passed over  704\n",
            "Training on the rank 0...:  21% 150/704 [01:07<03:59,  2.31it/s]- On Training: 150 was passed over  704\n",
            "Training on the rank 0...:  28% 200/704 [01:29<03:42,  2.27it/s]- On Training: 200 was passed over  704\n",
            "Training on the rank 0...:  36% 250/704 [01:51<03:30,  2.16it/s]- On Training: 250 was passed over  704\n",
            "Training on the rank 0...:  43% 300/704 [02:13<02:56,  2.29it/s]- On Training: 300 was passed over  704\n",
            "Training on the rank 0...:  50% 350/704 [02:35<02:34,  2.30it/s]- On Training: 350 was passed over  704\n",
            "Training on the rank 0...:  57% 400/704 [02:57<02:12,  2.29it/s]- On Training: 400 was passed over  704\n",
            "Training on the rank 0...:  64% 450/704 [03:19<01:53,  2.23it/s]- On Training: 450 was passed over  704\n",
            "Training on the rank 0...:  71% 500/704 [03:42<01:32,  2.20it/s]- On Training: 500 was passed over  704\n",
            "Training on the rank 0...:  78% 550/704 [04:04<01:06,  2.31it/s]- On Training: 550 was passed over  704\n",
            "Training on the rank 0...:  85% 600/704 [04:26<00:45,  2.31it/s]- On Training: 600 was passed over  704\n",
            "Training on the rank 0...:  92% 650/704 [04:48<00:24,  2.24it/s]- On Training: 650 was passed over  704\n",
            "Training on the rank 0...:  99% 700/704 [05:11<00:01,  2.23it/s]- On Training: 700 was passed over  704\n",
            "Evaluating on the rank 0 ...:   0% 0/79 [00:00<?, ?it/s]- On Evaluating: 0 was passed over  79\n",
            "Evaluating on the rank 0 ...:  63% 50/79 [00:19<00:11,  2.46it/s]- On Evaluating: 50 was passed over  79\n",
            "--------------|     On process 0      |----------------\n",
            "Epoch: 03 | Epoch Time: 6m 10s\n",
            "\tTrain Loss: 2.347 | Train Acc: 11.90%\n",
            "\t Val. Loss: 2.083 |  Val. Acc: 19.42%\n",
            "/content/main.py:285: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ddp_model.load_state_dict(torch.load(f'{root}mlp-model.pt'))\n",
            "Testing on the rank 0 ...:   0% 0/157 [00:00<?, ?it/s]- On Testing: 0 was passed over  157\n",
            "Testing on the rank 0 ...:  32% 50/157 [00:19<00:42,  2.53it/s]- On Testing: 50 was passed over  157\n",
            "Testing on the rank 0 ...:  64% 100/157 [00:40<00:24,  2.34it/s]- On Testing: 100 was passed over  157\n",
            "Testing on the rank 0 ...:  96% 150/157 [00:59<00:02,  2.60it/s]- On Testing: 150 was passed over  157\n",
            "Test results on process 0: Test Loss: 2.132 | Test Acc: 19.86%\n",
            "Process 0 finished training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_training_metrics_seq2seq(json_file_1gpu, json_file_2gpus):\n",
        "    \"\"\"\n",
        "    Generates plots comparing training metrics from 1-GPU and 2-GPU setups for a seq2seq model.\n",
        "    Includes plots for rank 0, rank 1, and their average for the 2-GPU setup.\n",
        "    \"\"\"\n",
        "    # Load 1-GPU data\n",
        "    with open(json_file_1gpu, 'r') as f:\n",
        "        data_1gpu = json.load(f)\n",
        "\n",
        "    seq2seq_1gpu = data_1gpu[list(data_1gpu.keys())[0]]\n",
        "\n",
        "    # Load 2-GPU data\n",
        "    with open(json_file_2gpus, 'r') as f:\n",
        "        data_2gpus = json.load(f)\n",
        "    seq2seq_2gpus_rank0 = data_2gpus[list(data_2gpus.keys())[0]]\n",
        "    seq2seq_2gpus_rank1 = data_2gpus[list(data_2gpus.keys())[1]]\n",
        "\n",
        "    # Extract data for 1 GPU\n",
        "    train_times_1gpu = seq2seq_1gpu['training_times']\n",
        "    train_losses_1gpu = seq2seq_1gpu['train_losses']\n",
        "    val_times_1gpu = seq2seq_1gpu['validation_times']\n",
        "    val_losses_1gpu = seq2seq_1gpu['validation_losses']\n",
        "    epoch_times_1gpu = seq2seq_1gpu['epoch_times']\n",
        "    train_accuracy_1gpu = seq2seq_1gpu['train_accuracy']\n",
        "    validation_accuracy_1gpu = seq2seq_1gpu['validation_accuracy']\n",
        "\n",
        "    # Extract data for 2 GPUs (rank 0)\n",
        "    train_times_2gpus_rank0 = seq2seq_2gpus_rank0['training_times']\n",
        "    train_losses_2gpus_rank0 = seq2seq_2gpus_rank0['train_losses']\n",
        "    val_times_2gpus_rank0 = seq2seq_2gpus_rank0['validation_times']\n",
        "    val_losses_2gpus_rank0 = seq2seq_2gpus_rank0['validation_losses']\n",
        "    epoch_times_2gpus_rank0 = seq2seq_2gpus_rank0['epoch_times']\n",
        "    train_accuracy_2gpus_rank0 = seq2seq_2gpus_rank0['train_accuracy']\n",
        "    validation_accuracy_2gpus_rank0 = seq2seq_2gpus_rank0['validation_accuracy']\n",
        "\n",
        "\n",
        "    # Extract data for 2 GPUs (rank 1)\n",
        "    train_times_2gpus_rank1 = seq2seq_2gpus_rank1['training_times']\n",
        "    train_losses_2gpus_rank1 = seq2seq_2gpus_rank1['train_losses']\n",
        "    val_times_2gpus_rank1 = seq2seq_2gpus_rank1['validation_times']\n",
        "    val_losses_2gpus_rank1 = seq2seq_2gpus_rank1['validation_losses']\n",
        "    epoch_times_2gpus_rank1 = seq2seq_2gpus_rank1['epoch_times']\n",
        "    train_accuracy_2gpus_rank1 = seq2seq_2gpus_rank1['train_accuracy']\n",
        "    validation_accuracy_2gpus_rank1 = seq2seq_2gpus_rank1['validation_accuracy']\n",
        "\n",
        "\n",
        "    # Calculate averages for 2 GPUs\n",
        "    train_times_2gpus_avg = np.mean([train_times_2gpus_rank0, train_times_2gpus_rank1], axis=0)\n",
        "    train_losses_2gpus_avg = np.mean([train_losses_2gpus_rank0, train_losses_2gpus_rank1], axis=0)\n",
        "    val_times_2gpus_avg = np.mean([val_times_2gpus_rank0, val_times_2gpus_rank1], axis=0)\n",
        "    val_losses_2gpus_avg = np.mean([val_losses_2gpus_rank0, val_losses_2gpus_rank1], axis=0)\n",
        "    epoch_times_2gpus_avg = np.mean([epoch_times_2gpus_rank0, epoch_times_2gpus_rank1], axis=0)\n",
        "    train_accuracy_2gpus_avg = np.mean([train_accuracy_2gpus_rank0, train_accuracy_2gpus_rank1], axis=0)\n",
        "    validation_accuracy_2gpus_avg = np.mean([validation_accuracy_2gpus_rank0, validation_accuracy_2gpus_rank1], axis=0)\n",
        "\n",
        "\n",
        "    # Epochs for x-axis\n",
        "    epochs = list(range(len(train_times_1gpu)))\n",
        "\n",
        "    # Plot Training Times\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_times_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, train_times_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, train_times_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, train_times_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Training Time (s)')\n",
        "    plt.title('Training Time Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Training Losses\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_losses_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, train_losses_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, train_losses_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, train_losses_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Training Loss')\n",
        "    plt.title('Training Loss Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Validation Times\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, val_times_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, val_times_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, val_times_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, val_times_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Validation Time (s)')\n",
        "    plt.title('Validation Time Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Validation Losses\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, val_losses_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, val_losses_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, val_losses_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, val_losses_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Validation Loss')\n",
        "    plt.title('Validation Loss Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Test Losses\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, epoch_times_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, epoch_times_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, epoch_times_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, epoch_times_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Test Loss')\n",
        "    plt.title('Epochs Time Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Training Accurcy\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, train_accuracy_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, train_accuracy_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, train_accuracy_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, train_accuracy_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Training Accurcy')\n",
        "    plt.title('Training Accurcy Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Validation Accurcy\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, validation_accuracy_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, validation_accuracy_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, validation_accuracy_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, validation_accuracy_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Validation Accurcy')\n",
        "    plt.title('Validation Accurcy Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Test Accurcy\n",
        "    ''' plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, test_Accurcys_1gpu, label='1 GPU', marker='o')\n",
        "    plt.plot(epochs, test_Accurcys_2gpus_rank0, label='2 GPUs (Rank 0)', marker='o')\n",
        "    plt.plot(epochs, test_Accurcys_2gpus_rank1, label='2 GPUs (Rank 1)', marker='o')\n",
        "    plt.plot(epochs, test_Accurcys_2gpus_avg, label='2 GPUs (Average)', marker='o', linestyle='--')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Test Accurcy')\n",
        "    plt.title('Test Accurcy Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()'''\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    plot_training_metrics_seq2seq('/content/LeNet_10epochs_1GPU.json', '/content/LeNet_10epochs_2GPU.json')"
      ],
      "metadata": {
        "id": "GIJj9pO6vbmE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}